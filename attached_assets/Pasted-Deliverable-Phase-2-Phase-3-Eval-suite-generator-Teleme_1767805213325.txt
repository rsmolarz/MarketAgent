Deliverable: Phase 2 + Phase 3 + Eval suite generator + Telemetry ingestion + Prompt-Tuning Agent

Everything below is designed to drop into your repo with minimal disruption. It assumes:

Agents are importable as agents.<module>

Prompt files live in agents/prompts/*.md

You want human-approved PRs (auto-created, not auto-merged)

A) Phase 2 — Auto-optimize prompts only + human-approved PRs
A1) Add prompt inventory + policy
meta/policy.yaml (extend)
auto_patch: true
patch_mode: prompts_only

protected_paths:
  - ".github/"
  - "infra/"
  - "secrets/"
  - "trading/"
  - "allocation/"
  - "tools/llm_client.py"

allowed_patch_globs:
  - "agents/prompts/*.md"

max_patch:
  max_files_changed: 6
  max_lines_changed: 250

thresholds:
  min_total_score: 80
  min_success_rate: 0.80
  max_schema_violation_rate: 0.02

prompt_tuning:
  n_candidates: 3
  max_prompt_delta_lines: 120
  enforce_no_new_tools: true

Add prompt folder
agents/prompts/
  meta_system.md
  reviewer.md
  agent_guidelines.md
  prompt_tuner.md

agents/prompts/agent_guidelines.md
Global constraints for all agents:
- Prefer tool outputs and deterministic logic over speculation.
- Keep outputs schema-valid where required.
- Never propose actions that touch protected paths.
- When uncertain, say so and request the missing input (unless an eval case requires a default).

agents/prompts/prompt_tuner.md
You are the Prompt-Tuning Agent.

You will be given:
- current prompt text
- evaluation failures and patterns
- constraints and guardrails

Goal:
- produce an improved prompt that increases eval pass rate and reduces instability
- preserve intent and tone
- minimal edits preferred

Hard constraints:
- modify ONLY the prompt text provided
- do not add new tools or permissions
- output plain text only (the updated prompt), no markdown fences, no commentary

A2) Prompt-Tuning Agent (core)
meta/prompt_tuner.py
import json
from pathlib import Path
from tools.llm_client import call_llm

def tune_prompt(prompt_path: str, failure_summary: dict, policy: dict) -> str:
    prompt_text = Path(prompt_path).read_text()

    system = Path("agents/prompts/prompt_tuner.md").read_text()
    guidelines = Path("agents/prompts/agent_guidelines.md").read_text()

    user_payload = {
        "prompt_path": prompt_path,
        "current_prompt": prompt_text,
        "failures": failure_summary,
        "guardrails": policy.get("prompt_tuning", {}),
        "constraints": {
            "allowed_patch_globs": policy.get("allowed_patch_globs", []),
            "max_prompt_delta_lines": policy.get("prompt_tuning", {}).get("max_prompt_delta_lines", 120),
        }
    }

    msgs = [
        {"role": "system", "content": system},
        {"role": "system", "content": guidelines},
        {"role": "user", "content": json.dumps(user_payload)}
    ]

    # plain text response required
    out = call_llm(msgs, temperature=0.2, max_tokens=2200)
    # llm_client uses JSON mode currently; for prompt tuning we want raw text.
    # If you keep JSON mode, then require {"updated_prompt": "..."} and extract.
    if isinstance(out, dict) and "updated_prompt" in out:
        return out["updated_prompt"]
    # fallback if your llm client returns raw string in future
    if isinstance(out, str):
        return out
    raise RuntimeError("Prompt tuner returned unexpected format.")


Important: Your current tools/llm_client.py enforces JSON response format. For prompt tuning, easiest is to make the tuner output JSON with one key.

Update agents/prompts/prompt_tuner.md last line to:

Output STRICT JSON: {"updated_prompt":"..."}.

Do that now:

Replace last line in agents/prompts/prompt_tuner.md with:
Output STRICT JSON only: {"updated_prompt":"<the full updated prompt text>"}

A3) Meta-Agent now generates prompt-change PR (prompts only)
meta/meta_agent.py (add patching logic)

Add these helper functions:

import fnmatch
import subprocess
from pathlib import Path
from meta.prompt_tuner import tune_prompt

def allowed_prompt_file(path: str, policy: dict) -> bool:
    allowed = policy.get("allowed_patch_globs", [])
    return any(fnmatch.fnmatch(path, g) for g in allowed)

def write_prompt_patch(prompt_path: str, new_text: str):
    Path(prompt_path).write_text(new_text)

def git(cmd):
    return subprocess.check_output(["bash","-lc", cmd], text=True).strip()

def diff_line_count():
    return int(git("git diff --numstat | awk '{add+=$1; del+=$2} END {print add+del+0}'"))

def files_changed_count():
    return int(git("git diff --name-only | wc -l"))

def stage_and_commit(title: str):
    git("git add agents/prompts/*.md || true")
    git(f"git commit -m {json.dumps(title)} || true")


Then in main() after you produce review + eval_summaries, add:

# Identify failures (simple: any agent < success threshold)
failures = [e for e in eval_summaries if e["success_rate"] < policy["thresholds"]["min_success_rate"]]

if policy.get("auto_patch") and policy.get("patch_mode") == "prompts_only":
    # Tune specific prompts (you can map prompts per agent later; start with global prompts)
    prompt_targets = [
        "agents/prompts/meta_system.md",
        "agents/prompts/reviewer.md",
        "agents/prompts/agent_guidelines.md",
    ]

    patch_budget = policy.get("max_patch", {})
    tuned_any = False

    failure_summary = {
        "eval_summaries": eval_summaries,
        "top_failures": [f.get("failures", []) for f in failures][:3],
        "meta_review": review
    }

    for p in prompt_targets:
        if not allowed_prompt_file(p, policy):
            continue
        updated = tune_prompt(p, failure_summary, policy)
        if updated and updated.strip() != Path(p).read_text().strip():
            write_prompt_patch(p, updated)
            tuned_any = True

        if files_changed_count() > patch_budget.get("max_files_changed", 6):
            break
        if diff_line_count() > patch_budget.get("max_lines_changed", 250):
            break

    if tuned_any:
        stage_and_commit("Meta-Agent: prompt improvements (prompts-only)")


This will create a commit when prompts changed. GitHub Actions will open a PR (next section).

A4) GitHub Action that opens a PR (human-approved)

Add:

.github/workflows/prompt_tuning_pr.yml
name: Prompt Tuning PR (Meta-Agent)

on:
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:
  pull_request:

jobs:
  tune_prompts:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch main for diff base
        run: |
          git fetch origin main:refs/remotes/origin/main

      - name: Run eval suites
        run: |
          python - <<'EOF'
          import yaml
          from pathlib import Path
          from eval.harness import run_suite

          m = yaml.safe_load(Path("agents/manifest.yaml").read_text())
          for a in m["agents"]:
              out = f"eval/results/{a['name']}.json"
              run_suite(a["module"], a["entrypoint"], a["eval_suite"], out)
          EOF

      - name: Run Meta-Agent (may commit prompt changes)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: gpt-4.1-mini
        run: |
          python meta/meta_agent.py

      - name: Create PR if changes exist
        uses: peter-evans/create-pull-request@v6
        with:
          branch: meta/prompt-tuning
          title: "Meta-Agent: Prompt improvements (prompts-only)"
          body: |
            Automated prompt-only improvements generated by Meta-Agent.
            - Scope restricted to agents/prompts/*.md
            - Please review changes and ensure eval results improve.
          labels: meta-agent,prompt-tuning


This produces PRs you approve manually.

B) Auto-generate eval suites per agent
B1) Generator script
eval/generate_suites.py
import json
import yaml
from pathlib import Path

DEFAULT_CASES = [
    {
        "id": "smoke_1",
        "input": {"text": "Return a one-sentence summary."}
    },
    {
        "id": "smoke_2",
        "input": {"text": "List 3 risks and 3 mitigations."}
    },
]

def infer_suite_name(agent_name: str) -> str:
    return f"eval/suites/{agent_name}.jsonl"

def main():
    manifest = yaml.safe_load(Path("agents/manifest.yaml").read_text())
    Path("eval/suites").mkdir(parents=True, exist_ok=True)

    for a in manifest["agents"]:
        suite_path = Path(a.get("eval_suite") or infer_suite_name(a["name"]))
        if suite_path.exists():
            continue

        # Minimal: smoke tests; you can expand later per agent role
        lines = []
        for c in DEFAULT_CASES:
            # keep generic kwargs; you should adapt per agent signature later
            lines.append(json.dumps(c))

        suite_path.write_text("\n".join(lines) + "\n")
        print(f"Created {suite_path}")

if __name__ == "__main__":
    main()

B2) Add a workflow to generate missing suites (optional)
.github/workflows/generate_eval_suites.yml
name: Generate Missing Eval Suites

on:
  workflow_dispatch:

jobs:
  gen:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - run: |
          python eval/generate_suites.py
          git add eval/suites || true
          git status --porcelain

      - uses: peter-evans/create-pull-request@v6
        with:
          branch: meta/add-eval-suites
          title: "Meta: Add missing eval suites"
          body: "Generated missing eval suites from manifest."
          labels: meta-agent,eval

C) Telemetry ingestion (latency/cost/error per agent)

You need one consistent event format. Do not overcomplicate.

C1) Event format

Write JSONL lines like:

{"ts":"2026-01-07T12:00:01Z","agent":"arbitrage_finder","run_id":"...","latency_ms":842,"tokens_in":1200,"tokens_out":420,"cost_usd":0.0061,"error":null}

C2) Logger utility
telemetry/logger.py
import json
import time
import uuid
from pathlib import Path
from datetime import datetime, timezone

LOG_PATH = Path("telemetry/events.jsonl")

def now_iso():
    return datetime.now(timezone.utc).isoformat()

def new_run_id():
    return str(uuid.uuid4())

def log_event(agent: str, run_id: str, latency_ms: int, tokens_in=None, tokens_out=None, cost_usd=None, error=None):
    LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
    event = {
        "ts": now_iso(),
        "agent": agent,
        "run_id": run_id,
        "latency_ms": latency_ms,
        "tokens_in": tokens_in,
        "tokens_out": tokens_out,
        "cost_usd": cost_usd,
        "error": error,
    }
    with LOG_PATH.open("a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")


You can instrument agents gradually. Start with Meta-Agent evaluation runs (easy).

C3) Telemetry summarizer used by Meta-Agent
telemetry/summarize.py
import json
from pathlib import Path
from collections import defaultdict

def summarize(path="telemetry/events.jsonl", last_n=2000):
    p = Path(path)
    if not p.exists():
        return {"available": False, "by_agent": {}}

    lines = p.read_text().splitlines()[-last_n:]
    by = defaultdict(lambda: {"count":0,"errors":0,"lat_ms":[],"cost":[]})

    for line in lines:
        try:
            e = json.loads(line)
        except:
            continue
        a = e.get("agent","unknown")
        by[a]["count"] += 1
        if e.get("error"):
            by[a]["errors"] += 1
        if e.get("latency_ms") is not None:
            by[a]["lat_ms"].append(e["latency_ms"])
        if e.get("cost_usd") is not None:
            by[a]["cost"].append(e["cost_usd"])

    out = {}
    for a,v in by.items():
        lat = sorted(v["lat_ms"])
        def pct(p):
            if not lat: return None
            i = int((p/100)* (len(lat)-1))
            return lat[i]
        out[a] = {
            "count": v["count"],
            "error_rate": (v["errors"]/v["count"]) if v["count"] else 0,
            "p50_latency_ms": pct(50),
            "p95_latency_ms": pct(95),
            "avg_cost_usd": (sum(v["cost"])/len(v["cost"])) if v["cost"] else None
        }

    return {"available": True, "by_agent": out}

C4) Add telemetry into Meta-Agent prompt

In meta/meta_agent.py, load telemetry summary and include it in the reviewer payload:

from telemetry.summarize import summarize as summarize_telemetry
telemetry_summary = summarize_telemetry()
# then include "telemetry": telemetry_summary in the user payload

D) Phase 3 — Sandbox self-modification for non-execution agents

You want this for “analysis-only” agents (geopolitics, sentiment, macro commentary), not anything that can place trades or allocate capital.

D1) Mark which agents are sandbox-eligible

Extend agents/manifest.yaml entries with:

sandbox_editable: true
execution_sensitive: false


For execution agents:

sandbox_editable: false
execution_sensitive: true

D2) Sandbox workflow that runs on a separate branch and never touches main
.github/workflows/sandbox_self_modify.yml
name: Sandbox Self-Modify (Non-Execution Agents)

on:
  workflow_dispatch:

jobs:
  sandbox:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run sandbox self-modifier
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: gpt-4.1-mini
        run: |
          python meta/sandbox_self_modifier.py

      - name: Create PR (sandbox only)
        uses: peter-evans/create-pull-request@v6
        with:
          branch: sandbox/self-modify
          title: "Sandbox: Non-execution agent improvements"
          body: |
            Sandbox-only self-modification run.
            - Only agents marked sandbox_editable=true were eligible
            - Protected paths and execution-sensitive agents excluded
            - Review carefully before merge
          labels: sandbox,meta-agent

D3) Sandbox self-modifier (restricted)
meta/sandbox_self_modifier.py

This version:

Only edits files under agents/ for agents flagged sandbox_editable: true

Never edits .github/, allocation/, trading/, etc.

Must pass eval harness before it will commit

import json, yaml, fnmatch, subprocess
from pathlib import Path
from tools.llm_client import call_llm

PROTECTED_PREFIXES = (".github/", "infra/", "secrets/", "trading/", "allocation/", "tools/")

def git(cmd):
    return subprocess.check_output(["bash","-lc", cmd], text=True).strip()

def is_protected(path: str) -> bool:
    return path.startswith(PROTECTED_PREFIXES)

def main():
    manifest = yaml.safe_load(Path("agents/manifest.yaml").read_text())
    editable = [a for a in manifest["agents"] if a.get("sandbox_editable") and not a.get("execution_sensitive")]

    if not editable:
        print("No sandbox-editable agents configured.")
        return

    # Build a constrained prompt asking for minimal diffs (JSON suggestions)
    payload = {
        "editable_agents": [{"name":a["name"],"module":a["module"],"entrypoint":a["entrypoint"]} for a in editable],
        "constraints": {
            "only_under": "agents/",
            "no_protected_prefixes": list(PROTECTED_PREFIXES),
            "max_files_changed": 4,
            "max_lines_changed": 200,
            "no_new_dependencies": True
        },
        "required_output": {
            "changes":[{"file":"agents/xxx.py","patch":"unified diff text"}]
        }
    }

    msgs = [
        {"role":"system","content":"You are a code improver operating in a sandbox. Output strict JSON only."},
        {"role":"user","content":json.dumps(payload)}
    ]

    plan = call_llm(msgs, temperature=0.2, max_tokens=2200)
    changes = plan.get("changes", [])

    # Apply patches (simple: write full file is safer; but we accept unified diffs only if you add a patch applier)
    # For now: block unified diff unless you add a safe patch applier.
    if changes:
        print("Sandbox plan returned changes, but patch apply is disabled by default.")
        print("Implement a safe patch applier before enabling.")
        return

if __name__ == "__main__":
    main()


Tell it like it is: applying unified diffs safely is where “self-modification” becomes a footgun. If you want this truly operational, implement a strict patch applier that:

only allows edits in agents/

rejects binary files

rejects edits that exceed budgets

rejects edits that touch imports of sensitive modules

If you want, I can give you that patch applier next; it’s ~150 lines and worth doing properly.

E) Final wiring checklist
Required secrets

OPENAI_API_KEY in GitHub repo secrets

Required pip deps

Update requirements.txt to include:

pyyaml==6.0.2

Required new files (summary)

agents/prompts/*

meta/prompt_tuner.py

eval/generate_suites.py

telemetry/logger.py

telemetry/summarize.py

workflows:

prompt_tuning_pr.yml

generate_eval_suites.yml

sandbox_self_modify.yml

What I need from you to finalize the manifest correctly (no back-and-forth)

Paste the function signatures (just the first line) for these files:

agents/arbitrage_finder_agent.py

agents/geopolitical_risk_agent.py

agents/macro_watcher_agent.py

agents/sentiment_divergence_*.py (whichever is primary)

Example:

def run(text: str, **kwargs):


With that, I will provide a ready-to-use agents/manifest.yaml and initial eval suites that match your real call signatures.

Arbitrage Finder Agent

Detects arbitrage opportunities across cryptocurrency exchanges
by comparing prices for the same assets.
"""

import ccxt
from typing import List, Dict, Any
from .base_agent import BaseAgent
from data_sources.coinbase_client import CoinbaseClient
from config import Config

class ArbitrageFinderAgent(BaseAgent):    
    """
    Finds arbitrage opportunities across crypto exchanges
    """
    
    def __init__(self):
        super().__init__()
        self.coinbase_client = CoinbaseClient()
        
        # Initialize exchanges
        self.exchanges = self._initialize_exchanges()
        
        # Common trading pairs to check (removed BNB since no Binance)
        self.trading_pairs = [
            'BTC/USD',
            'ETH/USD', 
            'ADA/USD',
            'SOL/USD',
            'MATIC/USD'
        ]
        
        self.min_profit_threshold = Config.ARBITRAGE_PROFIT_THRESHOLD
    
    def _initialize_exchanges(self) -> Dict[str, ccxt.Exchange]:
        """Initialize exchange connections"""
        exchanges = {}
        
        try:
            # Public-only exchanges (no API keys needed)
            exchanges['coinbase'] = ccxt.coinbase({
                'sandbox': False,
                'enableRateLimit': True,
            })
            Geopolitical Risk Agent

Monitors global geopolitical risks via news analysis with NLP-based 
risk scoring for hotspot regions.
"""

import os
import requests
import feedparser
import urllib.parse
import re
from typing import List, Dict, Any, Tuple
from datetime import datetime
from .base_agent import BaseAgent

try:
    from nltk.sentiment.vader import SentimentIntensityAnalyzer
    _sia = SentimentIntensityAnalyzer()
except Exception:
    _sia = None


class GeopoliticalRiskAgent(BaseAgent):
    """
    Monitors geopolitical risks through news analysis
    """
    
    RISK_KEYWORDS = [
        "war", "conflict", "attack", "military", "forces", "troops", "invasion",
        "sanction", "missile", "nuclear", "crisis", "tension", "clash", "protest",
        "escalation", "strike", "violence", "ceasefire", "hostility", "terror",
        "bomb", "airstrike", "shelling", "cyberattack"
    ]
    
    HOTSPOTS = {
        "Taiwan": "Taiwan China",
        "Ukraine": "Ukraine Russia",
        "Middle East": "Israel Gaza",
        "China-US": "China US conflict",
        "North Korea": "North Korea missile",
        "South China Sea": "South China Sea dispute"
    }
    
    def __init__(self):
        super().__init__()
        self.news_api_key = os.getenv("NEWS_API_KEY", "")
        
        # Read configuration from Config with fallbacks
        self.risk_threshold = self.config.get('risk_threshold', 50)
        self.max_articles_per_region = self.config.get('max_articles_per_region', 5)
        self.cache_size = 100
        """
Macro Watcher Agent

Monitors macroeconomic indicators for anomalies that could signal
market inefficiencies or regime changes.
"""

import yfinance as yf
from typing import List, Dict, Any
from datetime import datetime, timedelta
from .base_agent import BaseAgent
from data_sources.yahoo_finance_client import YahooFinanceClient

class MacroWatcherAgent(BaseAgent):
    """
    Monitors macro indicators like VIX, DXY, yield curves for anomalies
    """
    
    def __init__(self):
        super().__init__()
        self.yahoo_client = YahooFinanceClient()
        
        # Key macro indicators to monitor
        self.indicators = {
            '^VIX': {'name': 'VIX', 'high_threshold': 30, 'critical_threshold': 40},
            'DX-Y.NYB': {'name': 'Dollar Index', 'volatility_threshold': 0.02},
            '^TNX': {'name': '10Y Treasury', 'volatility_threshold': 0.1},
            '^IRX': {'name': '3M Treasury', 'volatility_threshold': 0.05},
            'SPY': {'name': 'S&P 500', 'volatility_threshold': 0.03}
        }
    
    def analyze(self) -> List[Dict[str, Any]]:
        """
        Analyze macro indicators for anomalies
        """
        findings = []
        
        for symbol, config in self.indicators.items():
            try:
                # Get recent data
                data = self.yahoo_client.get_price_data(symbol, period='5d')
                if data is None or len(data) < 2:
                    continue
                
                current_price = data['Close'].iloc[-1]
                previous_price = data['Close'].iloc[-2]
                
                # Calculate metrics
                daily_change = (current_price - previous_price) / previous_price
                volatility = data['Close'].pct_change().std()
                
                # Check for anomalies
                findings.extend(self._check_vix_spike(symbol, config, current_price, daily_change))
                findings.extend(self._check_volatility_spike(symbol, config, volatility, daily_change))
                findings.extend(self._check_yield_curve_inversion(symbol, config, data))
                
            except Exception as e:
                self.logger.error(f"Error analyzing {symbol}: {e}")                   price_data = self.yahoo_client.get_price_data(symbol, period='7d')
Thought for 21s

Below is a concrete, CI-safe way to wire your three real agents into the Meta-Agent pipeline without hitting live networks (ccxt/news/yfinance will break GitHub Actions unless you mock). This implements:

Manifest entries that match your class-based agents

A harness that calls Class.method

Eval adapters that inject fakes/fixtures so tests run offline

Initial eval suites for each agent

1) Update your manifest to use class methods + eval adapters
agents/manifest.yaml (add these entries)
agents:
  - name: arbitrage_finder
    module: agents.arbitrage_finder_agent
    callable: "ArbitrageFinderAgent.analyze"   # method will be called on a new instance
    eval_suite: eval/suites/arbitrage_finder.jsonl
    eval_adapter: eval.adapters:run_arbitrage_offline
    sandbox_editable: false
    execution_sensitive: true
    telemetry_tag: arbitrage

  - name: geopolitical_risk
    module: agents.geopolitical_risk_agent
    callable: "GeopoliticalRiskAgent.analyze"
    eval_suite: eval/suites/geopolitical_risk.jsonl
    eval_adapter: eval.adapters:run_geopolitical_offline
    sandbox_editable: true
    execution_sensitive: false
    telemetry_tag: geopolitics

  - name: macro_watcher
    module: agents.macro_watcher_agent
    callable: "MacroWatcherAgent.analyze"
    eval_suite: eval/suites/macro_watcher.jsonl
    eval_adapter: eval.adapters:run_macro_offline
    sandbox_editable: true
    execution_sensitive: false
    telemetry_tag: macro


Notes:

callable: "Class.method" is supported by the harness below.

eval_adapter is the offline-safe runner used during CI.

2) Replace harness with class/method + schema validation support
eval/harness.py
import json
import time
import importlib
from pathlib import Path
from typing import Any, Dict

def load_obj(module_path: str, dotted: str):
    """
    dotted: "Class.method" OR "function"
    Returns a callable runner: fn(**kwargs) -> output
    """
    mod = importlib.import_module(module_path)

    if "." in dotted:
        cls_name, meth_name = dotted.split(".", 1)
        cls = getattr(mod, cls_name)
        def runner(**kwargs):
            inst = cls()
            meth = getattr(inst, meth_name)
            return meth(**kwargs) if kwargs else meth()
        return runner

    fn = getattr(mod, dotted)
    def runner(**kwargs):
        return fn(**kwargs)
    return runner

def load_adapter(adapter_path: str):
    """
    "eval.adapters:run_macro_offline"
    """
    mod_path, fn_name = adapter_path.split(":")
    mod = importlib.import_module(mod_path)
    return getattr(mod, fn_name)

def validate_schema(output: Any, schema: Dict[str, Any]) -> (bool, str):
    """
    Minimal schema checks to keep it practical.
    """
    if not schema:
        return True, ""

    t = schema.get("type")
    if t == "list":
        if not isinstance(output, list):
            return False, f"Expected list, got {type(output)}"
        item = schema.get("item")
        if item and output:
            if item.get("type") == "dict":
                if not isinstance(output[0], dict):
                    return False, f"Expected list[dict], got list[{type(output[0])}]"
                required = item.get("required_keys", [])
                missing = [k for k in required if k not in output[0]]
                if missing:
                    return False, f"Missing keys in first item: {missing}"
        return True, ""

    if t == "dict":
        if not isinstance(output, dict):
            return False, f"Expected dict, got {type(output)}"
        required = schema.get("required_keys", [])
        missing = [k for k in required if k not in output]
        if missing:
            return False, f"Missing keys: {missing}"
        return True, ""

    return True, ""

def run_suite(module: str, callable_spec: str, suite_path: str, out_path: str, eval_adapter: str = ""):
    suite_lines = Path(suite_path).read_text().splitlines()
    results = []

    adapter_fn = load_adapter(eval_adapter) if eval_adapter else None
    runner = None if adapter_fn else load_obj(module, callable_spec)

    for line in suite_lines:
        if not line.strip():
            continue
        case = json.loads(line)
        case_id = case.get("id")
        kwargs = case.get("input", {}) or {}
        schema = case.get("schema", {}) or {}

        t0 = time.time()
        try:
            output = adapter_fn(case) if adapter_fn else runner(**kwargs)
            ok_schema, schema_err = validate_schema(output, schema)
            ok = ok_schema
            err = None if ok_schema else schema_err
        except Exception as e:
            output = None
            ok = False
            err = str(e)

        results.append({
            "id": case_id,
            "ok": ok,
            "latency_s": round(time.time() - t0, 4),
            "output_preview": (output[:1] if isinstance(output, list) else output) if output is not None else None,
            "error": err
        })

    Path(out_path).parent.mkdir(parents=True, exist_ok=True)
    Path(out_path).write_text(json.dumps({
        "module": module,
        "callable": callable_spec,
        "suite": suite_path,
        "results": results
    }, indent=2))

    return results

3) Add offline eval adapters (no network)
eval/adapters.py
import os
from datetime import datetime, timedelta
from typing import Any, Dict

def run_arbitrage_offline(case: Dict[str, Any]):
    """
    Offline: do not touch ccxt.
    Return a representative list[dict] shape your downstream expects.
    """
    # Example output shape – adjust keys to match your real arbitrage results format
    return [{
        "pair": "BTC/USD",
        "buy_exchange": "coinbase",
        "sell_exchange": "kraken",
        "buy_price": 50000.0,
        "sell_price": 50200.0,
        "profit_pct": 0.4,
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }]

def run_geopolitical_offline(case: Dict[str, Any]):
    """
    Offline: no NEWS_API_KEY, no HTTP.
    Produce a deterministic hotspot risk output.
    """
    return [{
        "region": "Taiwan",
        "risk_score": 72,
        "headline": "Tensions rise near Taiwan Strait in military drills",
        "source": "fixture",
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }]

def run_macro_offline(case: Dict[str, Any]):
    """
    Offline: no yfinance.
    Produce deterministic macro anomalies list.
    """
    return [{
        "symbol": "^VIX",
        "name": "VIX",
        "signal": "spike",
        "value": 35.2,
        "daily_change": 0.12,
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }]


This makes CI stable immediately. Then you can incrementally replace offline fixtures with realistic fixture-based calculations.

4) Create initial eval suites (schema-validated)
eval/suites/arbitrage_finder.jsonl
{"id":"arb_smoke_1","input":{},"schema":{"type":"list","item":{"type":"dict","required_keys":["pair","buy_exchange","sell_exchange","profit_pct"]}}}

eval/suites/geopolitical_risk.jsonl
{"id":"geo_smoke_1","input":{},"schema":{"type":"list","item":{"type":"dict","required_keys":["region","risk_score","headline"]}}}

eval/suites/macro_watcher.jsonl
{"id":"macro_smoke_1","input":{},"schema":{"type":"list","item":{"type":"dict","required_keys":["symbol","signal","value"]}}}

5) Update the workflow eval step to use callable + eval_adapter

Replace your “Run eval suites” step with:

- name: Run eval suites
  run: |
    python - <<'EOF'
    import yaml
    from pathlib import Path
    from eval.harness import run_suite

    m = yaml.safe_load(Path("agents/manifest.yaml").read_text())
    for a in m["agents"]:
        out = f"eval/results/{a['name']}.json"
        run_suite(
            module=a["module"],
            callable_spec=a["callable"],
            suite_path=a["eval_suite"],
            out_path=out,
            eval_adapter=a.get("eval_adapter","")
        )
    EOF

6) Telemetry ingestion (wire it into harness runs)

Add this to eval/harness.py after each case finishes (inside the loop), if you want:

telemetry/logger.py from earlier

record agent + latency_ms + error

Minimal patch inside loop:

from telemetry.logger import log_event, new_run_id

run_id = new_run_id()
# after each case:
log_event(agent=module, run_id=run_id, latency_ms=int((time.time()-t0)*1000), error=err)

7) Phase 2 prompt tuning PRs (works now)

Your Meta-Agent can now tune:

agents/prompts/meta_system.md

agents/prompts/reviewer.md

agents/prompts/agent_guidelines.md

and open a PR for review. Because evals are stable offline, the PR loop won’t flap.

8) Phase 3 sandbox self-modification (what changes now)

With the manifest flags:

sandbox_editable: true

execution_sensitive: false

your sandbox workflow will only ever consider agents like:

geopolitical

macro

sentiment

analyzers

and never execution agents like arbitrage/trading.

To operationalize sandbox code edits safely, you need a patch applier. If you want the Phase 3 workflow to actually apply edits (not just propose), implement this one file next:

meta/safe_patch_apply.py (strict unified-diff applier with path + budget enforcement)

If you confirm you want it enabled, I’ll provide that file (and the updated sandbox_self_modifier.py to use it) in the same format as above.